{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow_text","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:12:01.602212Z","iopub.execute_input":"2024-04-05T20:12:01.602535Z","iopub.status.idle":"2024-04-05T20:12:17.038436Z","shell.execute_reply.started":"2024-04-05T20:12:01.602507Z","shell.execute_reply":"2024-04-05T20:12:17.037499Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow_text in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: tensorflow-hub>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_text) (0.16.1)\nRequirement already satisfied: tensorflow<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_text) (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub>=0.13.0->tensorflow_text) (2.15.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow_datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:12:17.040227Z","iopub.execute_input":"2024-04-05T20:12:17.040526Z","iopub.status.idle":"2024-04-05T20:12:29.190096Z","shell.execute_reply.started":"2024-04-05T20:12:17.040500Z","shell.execute_reply":"2024-04-05T20:12:29.189011Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow_datasets in /opt/conda/lib/python3.10/site-packages (4.9.4)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.4.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (8.1.7)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.8)\nRequirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (1.6.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.26.4)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (3.20.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.31.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (0.14.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (2.4.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (4.66.1)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\nRequirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_datasets) (0.5.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2024.3.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.1.1)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.9.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.16.0)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.62.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import logging\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\nimport tensorflow_text","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:12:29.195430Z","iopub.execute_input":"2024-04-05T20:12:29.195692Z","iopub.status.idle":"2024-04-05T20:12:43.635579Z","shell.execute_reply.started":"2024-04-05T20:12:29.195665Z","shell.execute_reply":"2024-04-05T20:12:43.634806Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-05 20:12:32.671639: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-05 20:12:32.671738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-05 20:12:32.805103: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"physical_devices = tf.config.list_physical_devices('GPU')\n\nprint(\"GPU:\", tf.config.list_physical_devices('GPU'))\nprint(\"Num GPUs:\", len(physical_devices))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:12:43.636815Z","iopub.execute_input":"2024-04-05T20:12:43.637496Z","iopub.status.idle":"2024-04-05T20:12:43.822662Z","shell.execute_reply.started":"2024-04-05T20:12:43.637460Z","shell.execute_reply":"2024-04-05T20:12:43.821477Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\nNum GPUs: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"#first step is to download the data\nexamples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n                               with_info=True,\n                               as_supervised=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:12:43.824045Z","iopub.execute_input":"2024-04-05T20:12:43.824427Z","iopub.status.idle":"2024-04-05T20:13:57.359658Z","shell.execute_reply.started":"2024-04-05T20:12:43.824384Z","shell.execute_reply":"2024-04-05T20:13:57.358707Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset 124.94 MiB (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c2c49789e41481b813342117c543ecc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29f13883a59c4ac2bcaaafb0833d6ac8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2dafec6239d448ba0074a8ee64c83bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...:   0%|          | 0/51785 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incomplete55ARN7/ted_hrlr_translate-trai…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation examples...:   0%|          | 0/1193 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incomplete55ARN7/ted_hrlr_translate-vali…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test examples...:   0%|          | 0/1803 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incomplete55ARN7/ted_hrlr_translate-test…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset ted_hrlr_translate downloaded and prepared to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data, val_data = examples['train'], examples['validation']","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:57.361368Z","iopub.execute_input":"2024-04-05T20:13:57.361720Z","iopub.status.idle":"2024-04-05T20:13:57.366155Z","shell.execute_reply.started":"2024-04-05T20:13:57.361687Z","shell.execute_reply":"2024-04-05T20:13:57.365224Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nfor pt_examples, en_examples in train_data.batch(5).take(1):\n  print('> Examples in Portuguese:')\n  for pt in pt_examples.numpy():\n    print(pt.decode('utf-8'))\n  print()\n\n  print('> Examples in English:')\n  for en in en_examples.numpy():\n    print(en.decode('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:57.367418Z","iopub.execute_input":"2024-04-05T20:13:57.368042Z","iopub.status.idle":"2024-04-05T20:13:57.449823Z","shell.execute_reply.started":"2024-04-05T20:13:57.368011Z","shell.execute_reply":"2024-04-05T20:13:57.448937Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"> Examples in Portuguese:\ne quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\nmas e se estes fatores fossem ativos ?\nmas eles não tinham a curiosidade de me testar .\ne esta rebeldia consciente é a razão pela qual eu , como agnóstica , posso ainda ter fé .\n`` `` '' podem usar tudo sobre a mesa no meu corpo . ''\n\n> Examples in English:\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n't test for curiosity .\nand this conscious defiance is why i , as an agnostic , can still have faith .\nyou can use everything on the table on me .\n","output_type":"stream"}]},{"cell_type":"code","source":"#now the first step for transformer architectures is the tokenization, normally you will find that each model has its own tokenizr already provide, it converts\n#the data (words) into tokens or even sub-words in some cases according to the tokenizer\nmodel_name = 'ted_hrlr_translate_pt_en_converter'\ntf.keras.utils.get_file(\n    f'{model_name}.zip',\n    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n    cache_dir='.', cache_subdir='', extract=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:57.451081Z","iopub.execute_input":"2024-04-05T20:13:57.451368Z","iopub.status.idle":"2024-04-05T20:13:57.587474Z","shell.execute_reply.started":"2024-04-05T20:13:57.451345Z","shell.execute_reply":"2024-04-05T20:13:57.586563Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n184801/184801 [==============================] - 0s 0us/step\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'./ted_hrlr_translate_pt_en_converter.zip'"},"metadata":{}}]},{"cell_type":"code","source":"#this time the library provides 2 tokenizers one for english and other for portuguese\ntokenizers = tf.saved_model.load(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:57.592322Z","iopub.execute_input":"2024-04-05T20:13:57.592633Z","iopub.status.idle":"2024-04-05T20:13:58.424368Z","shell.execute_reply.started":"2024-04-05T20:13:57.592608Z","shell.execute_reply":"2024-04-05T20:13:58.423411Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#lets see what are the methods available to use\n[item for item in dir(tokenizers.en) if not item.startswith('_')]","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:58.428527Z","iopub.execute_input":"2024-04-05T20:13:58.429147Z","iopub.status.idle":"2024-04-05T20:13:58.436049Z","shell.execute_reply.started":"2024-04-05T20:13:58.429114Z","shell.execute_reply":"2024-04-05T20:13:58.435250Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['detokenize',\n 'get_reserved_tokens',\n 'get_vocab_path',\n 'get_vocab_size',\n 'lookup',\n 'tokenize',\n 'tokenizer',\n 'vocab']"},"metadata":{}}]},{"cell_type":"code","source":"print('> This is a batch of strings:')\nfor en in en_examples.numpy():\n  print(en.decode('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:58.437171Z","iopub.execute_input":"2024-04-05T20:13:58.437433Z","iopub.status.idle":"2024-04-05T20:13:58.446315Z","shell.execute_reply.started":"2024-04-05T20:13:58.437410Z","shell.execute_reply":"2024-04-05T20:13:58.445444Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"> This is a batch of strings:\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n't test for curiosity .\nand this conscious defiance is why i , as an agnostic , can still have faith .\nyou can use everything on the table on me .\n","output_type":"stream"}]},{"cell_type":"code","source":"encoded = tokenizers.en.tokenize(en_examples)\n\nprint('> This is a padded-batch of token IDs:')\nfor row in encoded.to_list():\n  print(row)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:13:58.447443Z","iopub.execute_input":"2024-04-05T20:13:58.447698Z","iopub.status.idle":"2024-04-05T20:14:00.423727Z","shell.execute_reply.started":"2024-04-05T20:13:58.447675Z","shell.execute_reply":"2024-04-05T20:14:00.422785Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"> This is a padded-batch of token IDs:\n[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n[2, 72, 81, 2508, 2159, 3072, 1282, 80, 192, 45, 13, 100, 111, 6040, 3176, 3186, 13, 94, 235, 89, 1938, 15, 3]\n[2, 79, 94, 212, 299, 92, 71, 1356, 92, 114, 15, 3]\n","output_type":"stream"}]},{"cell_type":"code","source":"#we have methods to go from words to tokens but also the other way around\nback2words = tokenizers.en.detokenize(encoded)\n\nprint('> This is human-readable text:')\nfor line in back2words.numpy():\n  print(line.decode('utf-8'))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:00.424935Z","iopub.execute_input":"2024-04-05T20:14:00.425200Z","iopub.status.idle":"2024-04-05T20:14:01.634263Z","shell.execute_reply.started":"2024-04-05T20:14:00.425178Z","shell.execute_reply":"2024-04-05T20:14:01.633278Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"> This is human-readable text:\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n ' t test for curiosity .\nand this conscious defiance is why i , as an agnostic , can still have faith .\nyou can use everything on the table on me .\n","output_type":"stream"}]},{"cell_type":"code","source":"#if we want a more detailed look about the tokenization we can see that using the lookup method\nprint('> This is the text split into tokens:')\ntokens = tokenizers.en.lookup(encoded)\ntokens\n#we can see that the tokenizer, besides converting the words into words or even sub-words, it adds special tokens for the start and end of the sequence, this is\n#specifically designed to help the transformer during training so that it is well defined one sequence in one language and the respective equivalent in the target\n#language","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:01.635658Z","iopub.execute_input":"2024-04-05T20:14:01.636023Z","iopub.status.idle":"2024-04-05T20:14:01.664975Z","shell.execute_reply.started":"2024-04-05T20:14:01.635994Z","shell.execute_reply":"2024-04-05T20:14:01.664116Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"> This is the text split into tokens:\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n  b'##ity', b'.', b'[END]']                                                 ,\n [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n  b'[END]']                                                           ,\n [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n  b'curiosity', b'.', b'[END]']                                          ,\n [b'[START]', b'and', b'this', b'conscious', b'de', b'##fi', b'##ance',\n  b'is', b'why', b'i', b',', b'as', b'an', b'ag', b'##no', b'##stic', b',',\n  b'can', b'still', b'have', b'faith', b'.', b'[END]']                     ,\n [b'[START]', b'you', b'can', b'use', b'everything', b'on', b'the',\n  b'table', b'on', b'me', b'.', b'[END]']                          ]>"},"metadata":{}}]},{"cell_type":"code","source":"lengths = []\n\nfor pt_examples, en_examples in train_data.batch(1024):\n  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n  lengths.append(pt_tokens.row_lengths())\n\n  en_tokens = tokenizers.en.tokenize(en_examples)\n  lengths.append(en_tokens.row_lengths())\n  print('.', end='', flush=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:41:19.058052Z","iopub.execute_input":"2024-04-05T20:41:19.058425Z","iopub.status.idle":"2024-04-05T20:41:23.810787Z","shell.execute_reply.started":"2024-04-05T20:41:19.058396Z","shell.execute_reply":"2024-04-05T20:41:23.810017Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"...................................................","output_type":"stream"}]},{"cell_type":"code","source":"#the next tep is to characterize our data, we want to identify what is the usual length of our sequences, we see that mostly all sequences are between 0 and 100 tokens \n#in length but there a few that are larger than that, specifically the largest is 320tokens\nall_lengths = np.concatenate(lengths)\n\nplt.hist(all_lengths, np.linspace(0, 500, 101))\nplt.ylim(plt.ylim())\nmax_length = max(all_lengths)\nplt.plot([max_length, max_length], plt.ylim())\nplt.title(f'Maximum tokens per example: {max_length}');","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:07.909769Z","iopub.execute_input":"2024-04-05T20:14:07.910065Z","iopub.status.idle":"2024-04-05T20:14:08.381817Z","shell.execute_reply.started":"2024-04-05T20:14:07.910040Z","shell.execute_reply":"2024-04-05T20:14:08.380873Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjkAAAGzCAYAAADNKAZOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5A0lEQVR4nO3deVyVZf7/8fdBPIALB00BGVE097VCQ1yykhGVLBtz0qxxS9PBJrWvpU3j0jRpi5qFaU6TzlROalNarhEqZu4k45I6VjpaimuCkoLC9fvDH/d4BLcCgavX8/E4j8c51/257/u6L2477+7tuIwxRgAAAJbxKe4OAAAAFAVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOcAUul0vjxo0r7m6UKH379lWFChWKuxsoYfi3gpKIkIMSZ/bs2XK5XHK5XFqzZk2+6cYYhYeHy+Vy6Z577imGHpZeBw8e1Lhx45SamlrcXQGu25kzZzRgwAA1adJEHo9HFSpUUPPmzTV16lSdO3fOqzYpKUn9+/dXvXr1VK5cOdWuXVuPPvqoDh06VOCy165dq7Zt26pcuXIKDQ3VH/7wB50+ffpGbBaKkG9xdwC4HH9/f82ZM0dt27b1ak9OTtZ3330nPz+/Iu/DmTNn5Otrzz+TgwcPavz48YqIiNAtt9xS3N0BrsuZM2e0Y8cOdenSRREREfLx8dHatWs1fPhwbdiwQXPmzHFqn376aZ04cUI9evRQ3bp19e233yohIUGLFi1SamqqQkNDndrU1FR16NBBDRs21OTJk/Xdd9/plVde0Z49e7R06dLi2FQUEnv+6w3rdOnSRfPnz9drr73mFTTmzJmjyMhIHTt2rMj74O/vX+TrQOmXm5ur7Oxs9pciVrlyZa1fv96rbfDgwfJ4PEpISNDkyZOd8DJ58mS1bdtWPj7/O2HRqVMntW/fXgkJCXr++eed9meeeUaVKlXSqlWrFBgYKEmKiIjQwIED9emnn6pjx443YOtQFDhdhRKrV69eOn78uBITE5227OxsffDBB3rooYcKnOeVV15R69atddNNNykgIECRkZH64IMPvGpmzZoll8ult99+26v9hRdekMvl0pIlS5y2S68zGDdunFwul/7zn//o4YcflsfjUdWqVfWnP/1JxhgdOHBA9913nwIDAxUaGqpJkyZ5rSPvVNy+ffu82letWiWXy6VVq1Y5bXfeeaeaNGmirVu3qn379ipXrpzq1KnjbE9ycrKioqIUEBCg+vXr67PPPrvieK5atUotW7aUJPXr1885JTh79mynZv78+YqMjFRAQICqVKmihx9+WN9///0Vlytd+D/hqlWr6s4773QO8X///ffq37+/QkJC5Ofnp8aNG+cb87ztnjdvnv7yl7+oevXq8vf3V4cOHfT111971e7Zs0fdu3dXaGio/P39Vb16dfXs2VPp6elX7FveOKakpKh169YKCAhQrVq1NGPGjHy1WVlZGjt2rOrUqSM/Pz+Fh4frqaeeUlZWlledy+XS0KFD9d5776lx48by8/PTsmXLrtiPpUuXql27dipfvrwqVqyouLg47dixw5m+YsUK+fj4aMyYMV7zzZkzRy6XS9OnT3faZs2apbvvvlvBwcHy8/NTo0aNvKbniYiI0D333KNVq1apRYsWCggIUNOmTZ397MMPP1TTpk3l7++vyMhIbdmyxWv+vOuvvv32W8XGxqp8+fIKCwvTc889J2PMFbdXurZ9QJL279+vXbt2XXV5lxMRESFJOnnypNN2xx13eAWcvLbKlStr586dTltGRoYSExP18MMPOwFHkn73u9+pQoUKmjdv3k/uF0oAA5Qws2bNMpLMpk2bTOvWrc0jjzziTFuwYIHx8fEx33//valZs6aJi4vzmrd69erm97//vUlISDCTJ082t99+u5FkFi1a5FV3zz33GI/HY/bv32+MMWbr1q3G7XabAQMGeNVJMmPHjnU+jx071kgyt9xyi+nVq5d54403TFxcnJFkJk+ebOrXr2+GDBli3njjDdOmTRsjySQnJ+fbtr1793qtZ+XKlUaSWblypdPWvn17ExYWZsLDw83IkSPN66+/bho1amTKlClj3n//fRMaGmrGjRtnXn31VfOrX/3KeDwek5GRcdlxTUtLM88995yRZAYNGmTeeecd884775hvvvnGq28tW7Y0U6ZMMaNGjTIBAQEmIiLC/PDDD85y+vTpY8qXL+983rhxo6lUqZL59a9/bX788UdnXdWrVzfh4eHmueeeM9OnTzf33nuvkWSmTJmSb7tvvfVWExkZaaZMmWLGjRtnypUrZ26//XanLisry9SqVcuEhYWZ559/3rz11ltm/PjxpmXLlmbfvn2X3eaLxzE4ONgMHTrUvPbaa6Zt27ZGkvnb3/7m1OXk5JiOHTuacuXKmWHDhpk333zTDB061Pj6+pr77rvPa5mSTMOGDU3VqlXN+PHjzbRp08yWLVsu24d//OMfxuVymU6dOpnXX3/dvPjiiyYiIsIEBQV57Qvx8fHG19fXpKSkGGOMOXjwoKlcubKJiYkxubm5Tl3Lli1N3759zZQpU8zrr79uOnbsaCSZhIQEr/XWrFnT1K9f31SrVs2MGzfOTJkyxfzqV78yFSpUMO+++66pUaOGmThxopk4caLxeDymTp06Jicnx5m/T58+xt/f39StW9c88sgjJiEhwdxzzz1GkvnTn/6Ub0wu/rdyrftA3t/oer6OsrKyzNGjR83+/fvNhx9+aEJDQ03NmjXNuXPnrjjfqVOnjNvtNoMGDXLa1qxZYySZuXPn5qtv27atue222665Xyh5CDkocS4OOQkJCaZixYrOl2ePHj3MXXfdZYwxBYacvLo82dnZpkmTJubuu+/2aj906JCpXLmy+fWvf22ysrLMrbfeamrUqGHS09O96i4Xci7+j+T58+dN9erVjcvlMhMnTnTaf/jhBxMQEGD69OmTb9uuNeRIMnPmzHHadu3aZSQZHx8fs379eqd9+fLlRpKZNWuWuZJNmzYVWJednW2Cg4NNkyZNzJkzZ5z2RYsWGUlmzJgxTtvFIWfNmjUmMDDQxMXFmbNnzzo1AwYMMNWqVTPHjh3zWk/Pnj2Nx+Nx/k55292wYUOTlZXl1E2dOtVIMtu2bTPGGLNlyxYjycyfP/+K21eQvHGcNGmS05aVlWVuueUWExwcbLKzs40xxrzzzjvGx8fHfP75517zz5gxw0gyX3zxhdOW9zfYsWPHVdd/6tQpExQUZAYOHOjVnpaWZjwej1d7ZmamqVOnjmncuLE5e/asiYuLM4GBgea///2v17yX7ufGGBMbG2tq167t1VazZk0jyaxdu9Zpy9tXAgICvJb75ptv5tsH+/TpYySZxx9/3GnLzc01cXFxxu12m6NHj3qNycX/Vq51HzDm+kPOP//5TyPJebVo0cJs3br1qvP9+c9/NpJMUlKS0zZ//nwjyaxevTpffY8ePUxoaOg19wslD6erUKL99re/1ZkzZ7Ro0SKdOnVKixYtuuypKkkKCAhw3v/www9KT09Xu3bt9OWXX3rVhYaGatq0aUpMTFS7du2Umpqqt99+2+tw9ZU8+uijzvsyZcqoRYsWMsZowIABTntQUJDq16+vb7/99lo3N58KFSqoZ8+ezuf69esrKChIDRs2VFRUlNOe9/6nrmvz5s06cuSIfv/733tdVxIXF6cGDRpo8eLF+eZZuXKlYmNj1aFDB3344YfOheDGGP3rX/9S165dZYzRsWPHnFdsbKzS09Pz/T369esnt9vtfG7Xrp3X9ng8HknS8uXL9eOPP1739vn6+uqxxx5zPrvdbj322GM6cuSIUlJSJF04VdewYUM1aNDAq8933323s70Xa9++vRo1anTVdScmJurkyZPq1auX13LLlCmjqKgor+WWK1dOs2fP1s6dO3XHHXdo8eLFmjJlimrUqOG1zIv38/T0dB07dkzt27fXt99+m+/0XaNGjRQdHe18zttX7r77bq/lXmkfGjp0qPM+71Rddnb2ZU+RXu8+sGrVqms6/ZXnrrvuUmJioubPn6/BgwerbNmyyszMvOI8q1ev1vjx4/Xb3/7W+ZtKFy5mllTgjQz+/v7OdJROXHiMEq1q1aqKiYnRnDlz9OOPPyonJ0cPPPDAZesXLVqk559/XqmpqV7XUbhcrny1PXv21LvvvqvFixdr0KBB6tChwzX369IvHY/HI39/f1WpUiVf+/Hjx695uZeqXr16vr57PB6Fh4fna5MuBLuf4r///a+kCyHqUg0aNMh3K//Zs2cVFxenyMhIzZs3z+vC8KNHj+rkyZOaOXOmZs6cWeD6jhw54vX50vGsVKmSpP9tT61atTRixAhNnjxZ7733ntq1a6d7773XuS7qasLCwlS+fHmvtnr16kmS9u3bp1atWmnPnj3auXOnqlatek19rlWr1lXXK124lkiS1xfrxS4N1m3atNGQIUM0bdo0xcbGqn///vnm+eKLLzR27FitW7cuX+hLT0/3GpOC9lVJ17wP+fj4qHbt2l5tF49dQX7KPnA9QkJCFBISIkl64IEH9MILL+jXv/619uzZ43XXVJ5du3bp/vvvV5MmTfTWW295TcsLjJdedyVd2M8vDpQofQg5KPEeeughDRw4UGlpaercubOCgoIKrPv8889177336o477tAbb7yhatWqqWzZspo1a5bXraV5jh8/rs2bN0uSvvrqK+Xm5ua7UPFyypQpc01tkrz+D7WgsCVJOTk517yea11XUfLz81OXLl20cOFCLVu2zOt5Rbm5uZKkhx9+WH369Clw/mbNmnl9vpbtmTRpkvr27auFCxfq008/1R/+8AdNmDBB69evV/Xq1X/uJik3N1dNmzbV5MmTC5x+aSi41i+/vPF45513CvwCvvQRBVlZWc6Fwd98841+/PFHlStXzpn+zTffqEOHDmrQoIEmT56s8PBwud1uLVmyRFOmTHHWl6c49qGfsg/8HA888ID++Mc/auHChV5H7CTpwIED6tixozwej5YsWaKKFSt6Ta9WrZokFfj8nEOHDiksLKzQ+okbj5CDEu/+++/XY489pvXr12vu3LmXrfvXv/4lf39/LV++3OvQ86xZswqsj4+P16lTpzRhwgSNHj1ar776qkaMGFHo/b9Y3hGKi+8Ckf53JKWoXS5k1axZU5K0e/fufEccdu/e7Uy/eDnvvfee7rvvPvXo0UNLly7VnXfeKenC0beKFSsqJydHMTExhdr/pk2bqmnTpnr22We1du1atWnTRjNmzPC6HbggBw8eVGZmptfRnP/85z+S/ndnzs0336x///vf6tChw2XH6ae4+eabJUnBwcHXNB5jx47Vzp079corr+jpp5/WqFGj9NprrznTP/nkE2VlZenjjz/2Okpz6em0wpKbm6tvv/3WOXoj5R+7SxXlPlCQvFNKl56qO378uDp27KisrCwlJSU5geZiTZo0ka+vrzZv3qzf/va3Tnt2drZSU1O92lD6cE0OSrwKFSpo+vTpGjdunLp27XrZujJlysjlcnkdFdm3b58WLFiQr/aDDz7Q3LlzNXHiRI0aNUo9e/bUs88+6/zHu6jkfeGtXr3aacvJybnsIf3Clvclf2nIatGihYKDgzVjxgyvw/ZLly7Vzp07FRcXl29ZbrdbH374oVq2bKmuXbtq48aNki78Hbp3765//etf2r59e775jh49et39zsjI0Pnz573amjZtKh8fnwJPM1zq/PnzevPNN53P2dnZevPNN1W1alVFRkZKunD91/fff6+//vWv+eY/c+bMVa/5uJzY2FgFBgbqhRdeyPdUXsl7PDZs2KBXXnlFw4YN05NPPqmRI0cqISFBycnJTk3eEZiLj7ikp6dfNswXhoSEBOe9MUYJCQkqW7bsZU/xXu8+cK23kB87dqzAI015p6BatGjhtGVmZqpLly76/vvvtWTJEtWtW7fAZXo8HsXExOjdd9/VqVOnnPZ33nlHp0+fVo8ePa7aL5RcHMlBqXC5Q94Xi4uL0+TJk9WpUyc99NBDOnLkiKZNm6Y6depo69atTt2RI0c0ZMgQ3XXXXc4FlQkJCVq5cqX69u2rNWvWXPNpq+vVuHFjtWrVSqNHj9aJEydUuXJlvf/++/m+wIvKzTffrKCgIM2YMUMVK1ZU+fLlFRUVpVq1aunFF19Uv3791L59e/Xq1UuHDx/W1KlTFRERoeHDhxe4vICAAC1atEh33323OnfurOTkZDVp0kQTJ07UypUrFRUVpYEDB6pRo0Y6ceKEvvzyS3322Wc6ceLEdfV7xYoVGjp0qHr06KF69erp/Pnzeuedd5wv06sJCwvTiy++qH379qlevXqaO3euUlNTNXPmTJUtW1aS9Mgjj2jevHkaPHiwVq5cqTZt2ignJ0e7du3SvHnztHz5cq8v0WsVGBio6dOn65FHHtFtt92mnj17qmrVqtq/f78WL16sNm3aKCEhQWfPnlWfPn1Ut25d/eUvf5EkjR8/Xp988on69eunbdu2qXz58urYsaPcbre6du2qxx57TKdPn9Zf//pXBQcHX/YnC34Of39/LVu2TH369FFUVJSWLl2qxYsX65lnnrns9UuSrmsf+N3vfqfk5OSrnip79913NWPGDHXr1k21a9fWqVOntHz5ciUmJqpr165eRyF79+6tjRs3qn///tq5c6fXs3EqVKigbt26OZ//8pe/qHXr1mrfvr0GDRqk7777TpMmTVLHjh3VqVOnnzBqKDGK45Yu4EouvoX8Sgq6hfxvf/ubqVu3rvHz8zMNGjQws2bNcm77zvOb3/zGVKxYMd/zVRYuXGgkmRdffNFp02VuIb/41llj8j87Jk/79u1N48aNvdq++eYbExMTY/z8/ExISIh55plnTGJiYoG3kF867+W2O6+v8fHx+dovtXDhQtOoUSPj6+ub73byuXPnmltvvdX4+fmZypUrm969e5vvvvvuqtt67Ngx06hRIxMaGmr27NljjDHm8OHDJj4+3oSHh5uyZcua0NBQ06FDBzNz5kxnvrxbyC+9NXzv3r1effv2229N//79zc0332z8/f1N5cqVzV133WU+++yzq25v3jhu3rzZREdHG39/f1OzZs18z5Qx5sKt9C+++KJp3Lix8fPzM5UqVTKRkZFm/PjxXo8XuNaxvtjKlStNbGys8Xg8xt/f39x8882mb9++ZvPmzcYYY4YPH27KlCljNmzY4DXf5s2bja+vrxkyZIjT9vHHH5tmzZoZf39/ExERYV588UXz9ttv53s8wfXsK3lj/vLLLztteX/rb775xnmGUEhIiBk7dqzX83TylnnxvxVjrm0fMObabyHftGmT6dGjh6lRo4bx8/Mz5cuXN7fddpuZPHlyvmfk5N0+X9CrZs2a+Zb9+eefm9atWxt/f39TtWpVEx8ff8XnTqF0cBlzg65UBIBicOedd+rYsWMFnjbBlfXt21cffPABP1SJUotrcgAAgJUIOQAAwEqEHAAAYCWuyQEAAFbiSA4AALASIQcAAFjpF/0wwNzcXB08eFAVK1Ys1Me4AwCAomOM0alTpxQWFnbFh7f+okPOwYMH8/3oHgAAKB0OHDhwxR/o/UWHnLxfoz1w4IACAwOLuTcAUAiyM6VJ9S+8f3K35C5/5XqgFMrIyFB4eHi+X5W/1C865OSdogoMDCTkALBDdhnJ7/+ffg8MJOTAale71IQLjwEAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACs5FvcHfglixi1OF/bvolxxdATAADsw5EcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYKXrCjkTJkxQy5YtVbFiRQUHB6tbt27avXu3V83Zs2cVHx+vm266SRUqVFD37t11+PBhr5r9+/crLi5O5cqVU3BwsEaOHKnz58971axatUq33Xab/Pz8VKdOHc2ePTtff6ZNm6aIiAj5+/srKipKGzduvJ7NAQAAFruukJOcnKz4+HitX79eiYmJOnfunDp27KjMzEynZvjw4frkk080f/58JScn6+DBg/rNb37jTM/JyVFcXJyys7O1du1a/f3vf9fs2bM1ZswYp2bv3r2Ki4vTXXfdpdTUVA0bNkyPPvqoli9f7tTMnTtXI0aM0NixY/Xll1+qefPmio2N1ZEjR37OeAAAAEu4jDHmp8589OhRBQcHKzk5WXfccYfS09NVtWpVzZkzRw888IAkadeuXWrYsKHWrVunVq1aaenSpbrnnnt08OBBhYSESJJmzJihp59+WkePHpXb7dbTTz+txYsXa/v27c66evbsqZMnT2rZsmWSpKioKLVs2VIJCQmSpNzcXIWHh+vxxx/XqFGjCuxvVlaWsrKynM8ZGRkKDw9Xenq6AgMDf+ow/GQRoxbna9s3Me6G9wOARbIzpRfCLrx/5qDkLl+8/QGKQEZGhjwez1W/v3/WNTnp6emSpMqVK0uSUlJSdO7cOcXExDg1DRo0UI0aNbRu3TpJ0rp169S0aVMn4EhSbGysMjIytGPHDqfm4mXk1eQtIzs7WykpKV41Pj4+iomJcWoKMmHCBHk8HucVHh7+czYfAACUYD855OTm5mrYsGFq06aNmjRpIklKS0uT2+1WUFCQV21ISIjS0tKcmosDTt70vGlXqsnIyNCZM2d07Ngx5eTkFFiTt4yCjB49Wunp6c7rwIED17/hAACgVPD9qTPGx8dr+/btWrNmTWH2p0j5+fnJz8+vuLsBAABugJ90JGfo0KFatGiRVq5cqerVqzvtoaGhys7O1smTJ73qDx8+rNDQUKfm0rut8j5frSYwMFABAQGqUqWKypQpU2BN3jIAAMAv23WFHGOMhg4dqo8++kgrVqxQrVq1vKZHRkaqbNmySkpKctp2796t/fv3Kzo6WpIUHR2tbdu2ed0FlZiYqMDAQDVq1MipuXgZeTV5y3C73YqMjPSqyc3NVVJSklMDAAB+2a7rdFV8fLzmzJmjhQsXqmLFis71Lx6PRwEBAfJ4PBowYIBGjBihypUrKzAwUI8//riio6PVqlUrSVLHjh3VqFEjPfLII3rppZeUlpamZ599VvHx8c6ppMGDByshIUFPPfWU+vfvrxUrVmjevHlavPh/dyONGDFCffr0UYsWLXT77bfr1VdfVWZmpvr161dYYwMAAEqx6wo506dPlyTdeeedXu2zZs1S3759JUlTpkyRj4+PunfvrqysLMXGxuqNN95wasuUKaNFixZpyJAhio6OVvny5dWnTx8999xzTk2tWrW0ePFiDR8+XFOnTlX16tX11ltvKTY21ql58MEHdfToUY0ZM0ZpaWm65ZZbtGzZsnwXIwMAgF+mn/WcnNLuWu+zLyo8JwdAoeM5OfgFuCHPyQEAACipCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKz0k3+7CkXj0tvKuaUcAICfhiM5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGCl6w45q1evVteuXRUWFiaXy6UFCxZ4Te/bt69cLpfXq1OnTl41J06cUO/evRUYGKigoCANGDBAp0+f9qrZunWr2rVrJ39/f4WHh+ull17K15f58+erQYMG8vf3V9OmTbVkyZLr3RwAAGCp6w45mZmZat68uaZNm3bZmk6dOunQoUPO65///KfX9N69e2vHjh1KTEzUokWLtHr1ag0aNMiZnpGRoY4dO6pmzZpKSUnRyy+/rHHjxmnmzJlOzdq1a9WrVy8NGDBAW7ZsUbdu3dStWzdt3779ejcJAABYyPd6Z+jcubM6d+58xRo/Pz+FhoYWOG3nzp1atmyZNm3apBYtWkiSXn/9dXXp0kWvvPKKwsLC9N577yk7O1tvv/223G63GjdurNTUVE2ePNkJQ1OnTlWnTp00cuRISdKf//xnJSYmKiEhQTNmzLjezQIAAJYpkmtyVq1apeDgYNWvX19DhgzR8ePHnWnr1q1TUFCQE3AkKSYmRj4+PtqwYYNTc8cdd8jtdjs1sbGx2r17t3744QenJiYmxmu9sbGxWrdu3WX7lZWVpYyMDK8XAACwU6GHnE6dOukf//iHkpKS9OKLLyo5OVmdO3dWTk6OJCktLU3BwcFe8/j6+qpy5cpKS0tzakJCQrxq8j5frSZvekEmTJggj8fjvMLDw3/exgIAgBLruk9XXU3Pnj2d902bNlWzZs108803a9WqVerQoUNhr+66jB49WiNGjHA+Z2RkEHQAALBUkd9CXrt2bVWpUkVff/21JCk0NFRHjhzxqjl//rxOnDjhXMcTGhqqw4cPe9Xkfb5azeWuBZIuXCsUGBjo9QIAAHYq8pDz3Xff6fjx46pWrZokKTo6WidPnlRKSopTs2LFCuXm5ioqKsqpWb16tc6dO+fUJCYmqn79+qpUqZJTk5SU5LWuxMRERUdHF/UmAQCAUuC6Q87p06eVmpqq1NRUSdLevXuVmpqq/fv36/Tp0xo5cqTWr1+vffv2KSkpSffdd5/q1Kmj2NhYSVLDhg3VqVMnDRw4UBs3btQXX3yhoUOHqmfPngoLC5MkPfTQQ3K73RowYIB27NihuXPnaurUqV6nmp544gktW7ZMkyZN0q5duzRu3Dht3rxZQ4cOLYRhAQAApd11h5zNmzfr1ltv1a233ipJGjFihG699VaNGTNGZcqU0datW3XvvfeqXr16GjBggCIjI/X555/Lz8/PWcZ7772nBg0aqEOHDurSpYvatm3r9Qwcj8ejTz/9VHv37lVkZKSefPJJjRkzxutZOq1bt9acOXM0c+ZMNW/eXB988IEWLFigJk2a/JzxAAAAlnAZY0xxd6K4ZGRkyOPxKD09vViuz4kYtfiqNfsmxt2AngCwRnam9MKFo+J65qDkLl+8/QGKwLV+f/PbVQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKvsXdAVxZxKjF+dr2TYwrhp4AAFC6cCQHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEq+xd2BX5KIUYuLuwsAAPxicCQHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFjpukPO6tWr1bVrV4WFhcnlcmnBggVe040xGjNmjKpVq6aAgADFxMRoz549XjUnTpxQ7969FRgYqKCgIA0YMECnT5/2qtm6davatWsnf39/hYeH66WXXsrXl/nz56tBgwby9/dX06ZNtWTJkuvdHAAAYKnrDjmZmZlq3ry5pk2bVuD0l156Sa+99ppmzJihDRs2qHz58oqNjdXZs2edmt69e2vHjh1KTEzUokWLtHr1ag0aNMiZnpGRoY4dO6pmzZpKSUnRyy+/rHHjxmnmzJlOzdq1a9WrVy8NGDBAW7ZsUbdu3dStWzdt3779ejcJAABYyGWMMT95ZpdLH330kbp16ybpwlGcsLAwPfnkk/q///s/SVJ6erpCQkI0e/Zs9ezZUzt37lSjRo20adMmtWjRQpK0bNkydenSRd99953CwsI0ffp0/fGPf1RaWprcbrckadSoUVqwYIF27dolSXrwwQeVmZmpRYsWOf1p1aqVbrnlFs2YMeOa+p+RkSGPx6P09HQFBgb+1GG4ZhGjFhfKcvZNjCuU5QCwUHam9ELYhffPHJTc5Yu3P0ARuNbv70K9Jmfv3r1KS0tTTEyM0+bxeBQVFaV169ZJktatW6egoCAn4EhSTEyMfHx8tGHDBqfmjjvucAKOJMXGxmr37t364YcfnJqL15NXk7eegmRlZSkjI8PrBQAA7FSoISctLU2SFBIS4tUeEhLiTEtLS1NwcLDXdF9fX1WuXNmrpqBlXLyOy9XkTS/IhAkT5PF4nFd4ePj1biIAACglflF3V40ePVrp6enO68CBA8XdJQAAUEQKNeSEhoZKkg4fPuzVfvjwYWdaaGiojhw54jX9/PnzOnHihFdNQcu4eB2Xq8mbXhA/Pz8FBgZ6vQAAgJ0KNeTUqlVLoaGhSkpKctoyMjK0YcMGRUdHS5Kio6N18uRJpaSkODUrVqxQbm6uoqKinJrVq1fr3LlzTk1iYqLq16+vSpUqOTUXryevJm89NosYtdjrBQAA8rvukHP69GmlpqYqNTVV0oWLjVNTU7V//365XC4NGzZMzz//vD7++GNt27ZNv/vd7xQWFubcgdWwYUN16tRJAwcO1MaNG/XFF19o6NCh6tmzp8LCLtwR8NBDD8ntdmvAgAHasWOH5s6dq6lTp2rEiBFOP5544gktW7ZMkyZN0q5duzRu3Dht3rxZQ4cO/fmjAgAASj3f651h8+bNuuuuu5zPecGjT58+mj17tp566illZmZq0KBBOnnypNq2batly5bJ39/fmee9997T0KFD1aFDB/n4+Kh79+567bXXnOkej0effvqp4uPjFRkZqSpVqmjMmDFez9Jp3bq15syZo2effVbPPPOM6tatqwULFqhJkyY/aSAAAIBdftZzckq70vqcnEvx3BwADp6Tg1+AYnlODgAAQElByAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwkm9xdwA/X8Soxfna9k2MK4aeAABQcnAkBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArFToIWfcuHFyuVxerwYNGjjTz549q/j4eN10002qUKGCunfvrsOHD3stY//+/YqLi1O5cuUUHByskSNH6vz58141q1at0m233SY/Pz/VqVNHs2fPLuxNAQAApViRHMlp3LixDh065LzWrFnjTBs+fLg++eQTzZ8/X8nJyTp48KB+85vfONNzcnIUFxen7OxsrV27Vn//+981e/ZsjRkzxqnZu3ev4uLidNdddyk1NVXDhg3To48+quXLlxfF5gAAgFLIt0gW6uur0NDQfO3p6en629/+pjlz5ujuu++WJM2aNUsNGzbU+vXr1apVK3366af66quv9NlnnykkJES33HKL/vznP+vpp5/WuHHj5Ha7NWPGDNWqVUuTJk2SJDVs2FBr1qzRlClTFBsbWxSbVOpEjFrs9XnfxLhi6gkAAMWjSI7k7NmzR2FhYapdu7Z69+6t/fv3S5JSUlJ07tw5xcTEOLUNGjRQjRo1tG7dOknSunXr1LRpU4WEhDg1sbGxysjI0I4dO5yai5eRV5O3jMvJyspSRkaG1wsAANip0ENOVFSUZs+erWXLlmn69Onau3ev2rVrp1OnTiktLU1ut1tBQUFe84SEhCgtLU2SlJaW5hVw8qbnTbtSTUZGhs6cOXPZvk2YMEEej8d5hYeH/9zNBQAAJVShn67q3Lmz875Zs2aKiopSzZo1NW/ePAUEBBT26q7L6NGjNWLECOdzRkYGQQcAAEsV+S3kQUFBqlevnr7++muFhoYqOztbJ0+e9Ko5fPiwcw1PaGhovrut8j5frSYwMPCKQcrPz0+BgYFeLwAAYKciDzmnT5/WN998o2rVqikyMlJly5ZVUlKSM3337t3av3+/oqOjJUnR0dHatm2bjhw54tQkJiYqMDBQjRo1cmouXkZeTd4yAAAACj3k/N///Z+Sk5O1b98+rV27Vvfff7/KlCmjXr16yePxaMCAARoxYoRWrlyplJQU9evXT9HR0WrVqpUkqWPHjmrUqJEeeeQR/fvf/9by5cv17LPPKj4+Xn5+fpKkwYMH69tvv9VTTz2lXbt26Y033tC8efM0fPjwwt4cAABQShX6NTnfffedevXqpePHj6tq1apq27at1q9fr6pVq0qSpkyZIh8fH3Xv3l1ZWVmKjY3VG2+84cxfpkwZLVq0SEOGDFF0dLTKly+vPn366LnnnnNqatWqpcWLF2v48OGaOnWqqlevrrfeeovbxwEAgMNljDHF3YnikpGRIY/Ho/T09Btyfc6lz665kXhODvALkZ0pvRB24f0zByV3+eLtD1AErvX7m9+uAgAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAl3+LuAG6Mgn4BnV8mBwDYjCM5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACv5FncHUHwiRi32+rxvYlwx9QQAgMLHkRwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWInfroLj0t+ykvg9KwBA6cWRHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlXhODq7o0mfn8NwcAEBpwZEcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABW4u4qXBd+qRwAUFpwJAcAAFiJkAMAAKxEyAEAAFbimhz8bDwVGQBQEnEkBwAAWIkjOUWkoLuQAADAjUPIQaHjNnMAQElAyMENwXU7AIAbjWtyAACAlUr9kZxp06bp5ZdfVlpampo3b67XX39dt99+e3F3C1fBKS0AQFEr1SFn7ty5GjFihGbMmKGoqCi9+uqrio2N1e7duxUcHFzc3cN14pQWAKAwuYwxprg78VNFRUWpZcuWSkhIkCTl5uYqPDxcjz/+uEaNGnXV+TMyMuTxeJSenq7AwMBC7Rt3V90YBCHgEtmZ0gthF94/c1Byly/e/gBF4Fq/v0vtkZzs7GylpKRo9OjRTpuPj49iYmK0bt26AufJyspSVlaW8zk9PV3ShcEqbLlZPxb6MpFfjeHzr1qzfXxsvrYmY5dftQYolbIzpaz///+uGRmSO6d4+wMUgbzv7asdpym1IefYsWPKyclRSEiIV3tISIh27dpV4DwTJkzQ+PHj87WHh4cXSR9RMnheLZwaoNSZGFbcPQCK1KlTp+TxeC47vdSGnJ9i9OjRGjFihPM5NzdXJ06c0E033SSXy1Vo68nIyFB4eLgOHDhQ6KfB8D+M843DWN8YjPONwTjfGEU5zsYYnTp1SmFhVw7ypTbkVKlSRWXKlNHhw4e92g8fPqzQ0NAC5/Hz85Ofn59XW1BQUFF1UYGBgfwDugEY5xuHsb4xGOcbg3G+MYpqnK90BCdPqX1OjtvtVmRkpJKSkpy23NxcJSUlKTo6uhh7BgAASoJSeyRHkkaMGKE+ffqoRYsWuv322/Xqq68qMzNT/fr1K+6uAQCAYlaqQ86DDz6oo0ePasyYMUpLS9Mtt9yiZcuW5bsY+Ubz8/PT2LFj850aQ+FinG8cxvrGYJxvDMb5xigJ41yqn5MDAABwOaX2mhwAAIArIeQAAAArEXIAAICVCDkAAMBKhBwAAGAlQk4RmDZtmiIiIuTv76+oqCht3LixuLtUqqxevVpdu3ZVWFiYXC6XFixY4DXdGKMxY8aoWrVqCggIUExMjPbs2eNVc+LECfXu3VuBgYEKCgrSgAEDdPr06Ru4FSXbhAkT1LJlS1WsWFHBwcHq1q2bdu/e7VVz9uxZxcfH66abblKFChXUvXv3fE8Y379/v+Li4lSuXDkFBwdr5MiROn/+/I3clBJv+vTpatasmfPU1+joaC1dutSZzjgXvokTJ8rlcmnYsGFOG+NcOMaNGyeXy+X1atCggTO9xI2zQaF6//33jdvtNm+//bbZsWOHGThwoAkKCjKHDx8u7q6VGkuWLDF//OMfzYcffmgkmY8++shr+sSJE43H4zELFiww//73v829995ratWqZc6cOePUdOrUyTRv3tysX7/efP7556ZOnTqmV69eN3hLSq7Y2Fgza9Yss337dpOammq6dOliatSoYU6fPu3UDB482ISHh5ukpCSzefNm06pVK9O6dWtn+vnz502TJk1MTEyM2bJli1myZImpUqWKGT16dHFsUon18ccfm8WLF5v//Oc/Zvfu3eaZZ54xZcuWNdu3bzfGMM6FbePGjSYiIsI0a9bMPPHEE04741w4xo4daxo3bmwOHTrkvI4ePepML2njTMgpZLfffruJj493Pufk5JiwsDAzYcKEYuxV6XVpyMnNzTWhoaHm5ZdfdtpOnjxp/Pz8zD//+U9jjDFfffWVkWQ2bdrk1CxdutS4XC7z/fff37C+lyZHjhwxkkxycrIx5sKYli1b1syfP9+p2blzp5Fk1q1bZ4y5EEZ9fHxMWlqaUzN9+nQTGBhosrKybuwGlDKVKlUyb731FuNcyE6dOmXq1q1rEhMTTfv27Z2QwzgXnrFjx5rmzZsXOK0kjjOnqwpRdna2UlJSFBMT47T5+PgoJiZG69atK8ae2WPv3r1KS0vzGmOPx6OoqChnjNetW6egoCC1aNHCqYmJiZGPj482bNhww/tcGqSnp0uSKleuLElKSUnRuXPnvMa5QYMGqlGjhtc4N23a1OsJ47GxscrIyNCOHTtuYO9Lj5ycHL3//vvKzMxUdHQ041zI4uPjFRcX5zWeEvtzYduzZ4/CwsJUu3Zt9e7dW/v375dUMse5VP+sQ0lz7Ngx5eTk5PtZiZCQEO3atauYemWXtLQ0SSpwjPOmpaWlKTg42Gu6r6+vKleu7NTgf3JzczVs2DC1adNGTZo0kXRhDN1ut4KCgrxqLx3ngv4OedPwP9u2bVN0dLTOnj2rChUq6KOPPlKjRo2UmprKOBeS999/X19++aU2bdqUbxr7c+GJiorS7NmzVb9+fR06dEjjx49Xu3bttH379hI5zoQc4BcuPj5e27dv15o1a4q7K9aqX7++UlNTlZ6erg8++EB9+vRRcnJycXfLGgcOHNATTzyhxMRE+fv7F3d3rNa5c2fnfbNmzRQVFaWaNWtq3rx5CggIKMaeFYzTVYWoSpUqKlOmTL4ryQ8fPqzQ0NBi6pVd8sbxSmMcGhqqI0eOeE0/f/68Tpw4wd/hEkOHDtWiRYu0cuVKVa9e3WkPDQ1Vdna2Tp486VV/6TgX9HfIm4b/cbvdqlOnjiIjIzVhwgQ1b95cU6dOZZwLSUpKio4cOaLbbrtNvr6+8vX1VXJysl577TX5+voqJCSEcS4iQUFBqlevnr7++usSuT8TcgqR2+1WZGSkkpKSnLbc3FwlJSUpOjq6GHtmj1q1aik0NNRrjDMyMrRhwwZnjKOjo3Xy5EmlpKQ4NStWrFBubq6ioqJueJ9LImOMhg4dqo8++kgrVqxQrVq1vKZHRkaqbNmyXuO8e/du7d+/32uct23b5hUoExMTFRgYqEaNGt2YDSmlcnNzlZWVxTgXkg4dOmjbtm1KTU11Xi1atFDv3r2d94xz0Th9+rS++eYbVatWrWTuz4V+KfMv3Pvvv2/8/PzM7NmzzVdffWUGDRpkgoKCvK4kx5WdOnXKbNmyxWzZssVIMpMnTzZbtmwx//3vf40xF24hDwoKMgsXLjRbt2419913X4G3kN96661mw4YNZs2aNaZu3brcQn6RIUOGGI/HY1atWuV1K+iPP/7o1AwePNjUqFHDrFixwmzevNlER0eb6OhoZ3reraAdO3Y0qampZtmyZaZq1arccnuJUaNGmeTkZLN3716zdetWM2rUKONyucynn35qjGGci8rFd1cZwzgXlieffNKsWrXK7N2713zxxRcmJibGVKlSxRw5csQYU/LGmZBTBF5//XVTo0YN43a7ze23327Wr19f3F0qVVauXGkk5Xv16dPHGHPhNvI//elPJiQkxPj5+ZkOHTqY3bt3ey3j+PHjplevXqZChQomMDDQ9OvXz5w6daoYtqZkKmh8JZlZs2Y5NWfOnDG///3vTaVKlUy5cuXM/fffbw4dOuS1nH379pnOnTubgIAAU6VKFfPkk0+ac+fO3eCtKdn69+9vatasadxut6latarp0KGDE3CMYZyLyqUhh3EuHA8++KCpVq2acbvd5le/+pV58MEHzddff+1ML2nj7DLGmMI/PgQAAFC8uCYHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFb6f8w+JS4bs3fgAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"MAX_TOKENS=128\ndef prepare_batch(pt, en):\n    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n\n    en = tokenizers.en.tokenize(en)\n    en = en[:, :(MAX_TOKENS+1)]\n    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n\n    return (pt, en_inputs), en_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:08.383069Z","iopub.execute_input":"2024-04-05T20:14:08.383382Z","iopub.status.idle":"2024-04-05T20:14:08.389477Z","shell.execute_reply.started":"2024-04-05T20:14:08.383356Z","shell.execute_reply":"2024-04-05T20:14:08.388388Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = 20000\nBATCH_SIZE = 64\ndef make_batches(ds):\n  return (\n      ds\n      .shuffle(BUFFER_SIZE)\n      .batch(BATCH_SIZE)\n      .map(prepare_batch, tf.data.AUTOTUNE)\n      .prefetch(buffer_size=tf.data.AUTOTUNE))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:08.390627Z","iopub.execute_input":"2024-04-05T20:14:08.390881Z","iopub.status.idle":"2024-04-05T20:14:08.399994Z","shell.execute_reply.started":"2024-04-05T20:14:08.390859Z","shell.execute_reply":"2024-04-05T20:14:08.399175Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Create training and validation set batches.\ntrain_batches = make_batches(train_data)\nval_batches = make_batches(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:08.400920Z","iopub.execute_input":"2024-04-05T20:14:08.401185Z","iopub.status.idle":"2024-04-05T20:14:08.800939Z","shell.execute_reply.started":"2024-04-05T20:14:08.401149Z","shell.execute_reply":"2024-04-05T20:14:08.799929Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for (pt, en), en_labels in train_batches.take(1):\n  break\n\nprint(pt.shape)\nprint(en.shape)\nprint(en_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:08.802285Z","iopub.execute_input":"2024-04-05T20:14:08.802634Z","iopub.status.idle":"2024-04-05T20:14:09.598104Z","shell.execute_reply.started":"2024-04-05T20:14:08.802604Z","shell.execute_reply":"2024-04-05T20:14:09.597193Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(64, 78)\n(64, 72)\n(64, 72)\n","output_type":"stream"}]},{"cell_type":"code","source":"def positional_encoding(length, depth):\n  depth = depth/2\n\n  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n\n  angle_rates = 1 / (10000**depths)         # (1, depth)\n  angle_rads = positions * angle_rates      # (pos, depth)\n\n  pos_encoding = np.concatenate(\n      [np.sin(angle_rads), np.cos(angle_rads)],\n      axis=-1) \n\n  return tf.cast(pos_encoding, dtype=tf.float32)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:09.599459Z","iopub.execute_input":"2024-04-05T20:14:09.599738Z","iopub.status.idle":"2024-04-05T20:14:09.605714Z","shell.execute_reply.started":"2024-04-05T20:14:09.599713Z","shell.execute_reply":"2024-04-05T20:14:09.604844Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n  def __init__(self, vocab_size, d_model):\n    super().__init__()\n    self.d_model = d_model\n    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n\n  def compute_mask(self, *args, **kwargs):\n    return self.embedding.compute_mask(*args, **kwargs)\n\n  def call(self, x):\n    length = tf.shape(x)[1]\n    x = self.embedding(x)\n    # This factor sets the relative scale of the embedding and positonal_encoding.\n    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n    x = x + self.pos_encoding[tf.newaxis, :length, :]\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:09.606999Z","iopub.execute_input":"2024-04-05T20:14:09.607412Z","iopub.status.idle":"2024-04-05T20:14:09.616995Z","shell.execute_reply.started":"2024-04-05T20:14:09.607375Z","shell.execute_reply":"2024-04-05T20:14:09.616145Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size(), d_model=512)\nembed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(), d_model=512)\n\npt_emb = embed_pt(pt)\nen_emb = embed_en(en)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:09.618062Z","iopub.execute_input":"2024-04-05T20:14:09.618800Z","iopub.status.idle":"2024-04-05T20:14:09.859073Z","shell.execute_reply.started":"2024-04-05T20:14:09.618772Z","shell.execute_reply":"2024-04-05T20:14:09.858280Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class BaseAttention(tf.keras.layers.Layer):\n  def __init__(self, **kwargs):\n    super().__init__()\n    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n    self.layernorm = tf.keras.layers.LayerNormalization()\n    self.add = tf.keras.layers.Add()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:09.860183Z","iopub.execute_input":"2024-04-05T20:14:09.860482Z","iopub.status.idle":"2024-04-05T20:14:09.865691Z","shell.execute_reply.started":"2024-04-05T20:14:09.860458Z","shell.execute_reply":"2024-04-05T20:14:09.864827Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class CrossAttention(BaseAttention):\n  def call(self, x, context):\n    attn_output, attn_scores = self.mha(\n        query=x,\n        key=context,\n        value=context,\n        return_attention_scores=True)\n\n    # Cache the attention scores for plotting later.\n    self.last_attn_scores = attn_scores\n\n    x = self.add([x, attn_output])\n    x = self.layernorm(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:09.866817Z","iopub.execute_input":"2024-04-05T20:14:09.867118Z","iopub.status.idle":"2024-04-05T20:14:09.880156Z","shell.execute_reply.started":"2024-04-05T20:14:09.867095Z","shell.execute_reply":"2024-04-05T20:14:09.879313Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"sample_ca = CrossAttention(num_heads=2, key_dim=512)\n\nprint(pt_emb.shape)\nprint(en_emb.shape)\nprint(sample_ca(en_emb, pt_emb).shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:09.887656Z","iopub.execute_input":"2024-04-05T20:14:09.888015Z","iopub.status.idle":"2024-04-05T20:14:10.121577Z","shell.execute_reply.started":"2024-04-05T20:14:09.887991Z","shell.execute_reply":"2024-04-05T20:14:10.120612Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(64, 78, 512)\n(64, 72, 512)\n(64, 72, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class GlobalSelfAttention(BaseAttention):\n  def call(self, x):\n    attn_output = self.mha(\n        query=x,\n        value=x,\n        key=x)\n    x = self.add([x, attn_output])\n    x = self.layernorm(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.122671Z","iopub.execute_input":"2024-04-05T20:14:10.122979Z","iopub.status.idle":"2024-04-05T20:14:10.128226Z","shell.execute_reply.started":"2024-04-05T20:14:10.122955Z","shell.execute_reply":"2024-04-05T20:14:10.127240Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n\nprint(pt_emb.shape)\nprint(sample_gsa(pt_emb).shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.129478Z","iopub.execute_input":"2024-04-05T20:14:10.129802Z","iopub.status.idle":"2024-04-05T20:14:10.180709Z","shell.execute_reply.started":"2024-04-05T20:14:10.129773Z","shell.execute_reply":"2024-04-05T20:14:10.179804Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(64, 78, 512)\n(64, 78, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class CausalSelfAttention(BaseAttention):\n  def call(self, x):\n    attn_output = self.mha(\n        query=x,\n        value=x,\n        key=x,\n        use_causal_mask = True)\n    x = self.add([x, attn_output])\n    x = self.layernorm(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.181983Z","iopub.execute_input":"2024-04-05T20:14:10.182354Z","iopub.status.idle":"2024-04-05T20:14:10.188636Z","shell.execute_reply.started":"2024-04-05T20:14:10.182321Z","shell.execute_reply":"2024-04-05T20:14:10.187608Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n\nprint(en_emb.shape)\nprint(sample_csa(en_emb).shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.189790Z","iopub.execute_input":"2024-04-05T20:14:10.190127Z","iopub.status.idle":"2024-04-05T20:14:10.245360Z","shell.execute_reply.started":"2024-04-05T20:14:10.190103Z","shell.execute_reply":"2024-04-05T20:14:10.244528Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"(64, 72, 512)\n(64, 72, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class FeedForward(tf.keras.layers.Layer):\n  def __init__(self, d_model, dff, dropout_rate=0.1):\n    super().__init__()\n    self.seq = tf.keras.Sequential([\n      tf.keras.layers.Dense(dff, activation='relu'),\n      tf.keras.layers.Dense(d_model),\n      tf.keras.layers.Dropout(dropout_rate)\n    ])\n    self.add = tf.keras.layers.Add()\n    self.layer_norm = tf.keras.layers.LayerNormalization()\n\n  def call(self, x):\n    x = self.add([x, self.seq(x)])\n    x = self.layer_norm(x) \n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.246617Z","iopub.execute_input":"2024-04-05T20:14:10.246977Z","iopub.status.idle":"2024-04-05T20:14:10.254709Z","shell.execute_reply.started":"2024-04-05T20:14:10.246945Z","shell.execute_reply":"2024-04-05T20:14:10.253709Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"sample_ffn = FeedForward(512, 2048)\n\nprint(en_emb.shape)\nprint(sample_ffn(en_emb).shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.255834Z","iopub.execute_input":"2024-04-05T20:14:10.256144Z","iopub.status.idle":"2024-04-05T20:14:10.430170Z","shell.execute_reply.started":"2024-04-05T20:14:10.256119Z","shell.execute_reply":"2024-04-05T20:14:10.429264Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"(64, 72, 512)\n(64, 72, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n    super().__init__()\n\n    self.self_attention = GlobalSelfAttention(\n        num_heads=num_heads,\n        key_dim=d_model,\n        dropout=dropout_rate)\n\n    self.ffn = FeedForward(d_model, dff)\n\n  def call(self, x):\n    x = self.self_attention(x)\n    x = self.ffn(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.431451Z","iopub.execute_input":"2024-04-05T20:14:10.431791Z","iopub.status.idle":"2024-04-05T20:14:10.439846Z","shell.execute_reply.started":"2024-04-05T20:14:10.431759Z","shell.execute_reply":"2024-04-05T20:14:10.438931Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n\nprint(pt_emb.shape)\nprint(sample_encoder_layer(pt_emb).shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.441037Z","iopub.execute_input":"2024-04-05T20:14:10.441299Z","iopub.status.idle":"2024-04-05T20:14:10.563726Z","shell.execute_reply.started":"2024-04-05T20:14:10.441277Z","shell.execute_reply":"2024-04-05T20:14:10.562673Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"(64, 78, 512)\n(64, 78, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n  def __init__(self, *, num_layers, d_model, num_heads,\n               dff, vocab_size, dropout_rate=0.1):\n    super().__init__()\n\n    self.d_model = d_model\n    self.num_layers = num_layers\n\n    self.pos_embedding = PositionalEmbedding(\n        vocab_size=vocab_size, d_model=d_model)\n\n    self.enc_layers = [\n        EncoderLayer(d_model=d_model,\n                     num_heads=num_heads,\n                     dff=dff,\n                     dropout_rate=dropout_rate)\n        for _ in range(num_layers)]\n    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n\n  def call(self, x):\n    # `x` is token-IDs shape: (batch, seq_len)\n    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n\n    # Add dropout.\n    x = self.dropout(x)\n\n    for i in range(self.num_layers):\n      x = self.enc_layers[i](x)\n\n    return x  # Shape `(batch_size, seq_len, d_model)`.","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.564856Z","iopub.execute_input":"2024-04-05T20:14:10.565132Z","iopub.status.idle":"2024-04-05T20:14:10.572829Z","shell.execute_reply.started":"2024-04-05T20:14:10.565107Z","shell.execute_reply":"2024-04-05T20:14:10.571943Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Instantiate the encoder.\nsample_encoder = Encoder(num_layers=4,\n                         d_model=512,\n                         num_heads=8,\n                         dff=2048,\n                         vocab_size=8500)\n\nsample_encoder_output = sample_encoder(pt, training=False)\n\n# Print the shape.\nprint(pt.shape)\nprint(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`.","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:10.574272Z","iopub.execute_input":"2024-04-05T20:14:10.574661Z","iopub.status.idle":"2024-04-05T20:14:11.029182Z","shell.execute_reply.started":"2024-04-05T20:14:10.574626Z","shell.execute_reply":"2024-04-05T20:14:11.027793Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"(64, 78)\n(64, 78, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n  def __init__(self,\n               *,\n               d_model,\n               num_heads,\n               dff,\n               dropout_rate=0.1):\n    super(DecoderLayer, self).__init__()\n\n    self.causal_self_attention = CausalSelfAttention(\n        num_heads=num_heads,\n        key_dim=d_model,\n        dropout=dropout_rate)\n\n    self.cross_attention = CrossAttention(\n        num_heads=num_heads,\n        key_dim=d_model,\n        dropout=dropout_rate)\n\n    self.ffn = FeedForward(d_model, dff)\n\n  def call(self, x, context):\n    x = self.causal_self_attention(x=x)\n    x = self.cross_attention(x=x, context=context)\n\n    # Cache the last attention scores for plotting later\n    self.last_attn_scores = self.cross_attention.last_attn_scores\n\n    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:11.031878Z","iopub.execute_input":"2024-04-05T20:14:11.032207Z","iopub.status.idle":"2024-04-05T20:14:11.039273Z","shell.execute_reply.started":"2024-04-05T20:14:11.032180Z","shell.execute_reply":"2024-04-05T20:14:11.038361Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n\nsample_decoder_layer_output = sample_decoder_layer(\n    x=en_emb, context=pt_emb)\n\nprint(en_emb.shape)\nprint(pt_emb.shape)\nprint(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:11.040237Z","iopub.execute_input":"2024-04-05T20:14:11.040517Z","iopub.status.idle":"2024-04-05T20:14:11.446280Z","shell.execute_reply.started":"2024-04-05T20:14:11.040494Z","shell.execute_reply":"2024-04-05T20:14:11.445043Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"(64, 72, 512)\n(64, 78, 512)\n(64, 72, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n               dropout_rate=0.1):\n    super(Decoder, self).__init__()\n\n    self.d_model = d_model\n    self.num_layers = num_layers\n\n    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n                                             d_model=d_model)\n    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n    self.dec_layers = [\n        DecoderLayer(d_model=d_model, num_heads=num_heads,\n                     dff=dff, dropout_rate=dropout_rate)\n        for _ in range(num_layers)]\n\n    self.last_attn_scores = None\n\n  def call(self, x, context):\n    # `x` is token-IDs shape (batch, target_seq_len)\n    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n\n    x = self.dropout(x)\n\n    for i in range(self.num_layers):\n      x  = self.dec_layers[i](x, context)\n\n    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n\n    # The shape of x is (batch_size, target_seq_len, d_model).\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:11.447414Z","iopub.execute_input":"2024-04-05T20:14:11.447705Z","iopub.status.idle":"2024-04-05T20:14:11.456521Z","shell.execute_reply.started":"2024-04-05T20:14:11.447678Z","shell.execute_reply":"2024-04-05T20:14:11.455531Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Instantiate the decoder.\nsample_decoder = Decoder(num_layers=4,\n                         d_model=512,\n                         num_heads=8,\n                         dff=2048,\n                         vocab_size=8000)\n\noutput = sample_decoder(\n    x=en,\n    context=pt_emb)\n\n# Print the shapes.\nprint(en.shape)\nprint(pt_emb.shape)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:11.457881Z","iopub.execute_input":"2024-04-05T20:14:11.458345Z","iopub.status.idle":"2024-04-05T20:14:12.082785Z","shell.execute_reply.started":"2024-04-05T20:14:11.458311Z","shell.execute_reply":"2024-04-05T20:14:12.081933Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"(64, 72)\n(64, 78, 512)\n(64, 72, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n  def __init__(self, *, num_layers, d_model, num_heads, dff,\n               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n    super().__init__()\n    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n                           num_heads=num_heads, dff=dff,\n                           vocab_size=input_vocab_size,\n                           dropout_rate=dropout_rate)\n\n    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n                           num_heads=num_heads, dff=dff,\n                           vocab_size=target_vocab_size,\n                           dropout_rate=dropout_rate)\n\n    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n\n  def call(self, inputs):\n    # To use a Keras model with `.fit` you must pass all your inputs in the\n    # first argument.\n    context, x  = inputs\n\n    context = self.encoder(context)  # (batch_size, context_len, d_model)\n\n    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n\n    # Final linear layer output.\n    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n\n    try:\n      # Drop the keras mask, so it doesn't scale the losses/metrics.\n      # b/250038731\n      del logits._keras_mask\n    except AttributeError:\n      pass\n\n    # Return the final output and the attention weights.\n    return logits","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:12.083863Z","iopub.execute_input":"2024-04-05T20:14:12.084169Z","iopub.status.idle":"2024-04-05T20:14:12.092725Z","shell.execute_reply.started":"2024-04-05T20:14:12.084129Z","shell.execute_reply":"2024-04-05T20:14:12.091874Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"num_layers = 4\nd_model = 128\ndff = 512\nnum_heads = 8\ndropout_rate = 0.1","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:12.093751Z","iopub.execute_input":"2024-04-05T20:14:12.094045Z","iopub.status.idle":"2024-04-05T20:14:12.106480Z","shell.execute_reply.started":"2024-04-05T20:14:12.094021Z","shell.execute_reply":"2024-04-05T20:14:12.105620Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"transformer = Transformer(\n    num_layers=num_layers,\n    d_model=d_model,\n    num_heads=num_heads,\n    dff=dff,\n    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n    dropout_rate=dropout_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:12.107562Z","iopub.execute_input":"2024-04-05T20:14:12.107868Z","iopub.status.idle":"2024-04-05T20:14:12.238678Z","shell.execute_reply.started":"2024-04-05T20:14:12.107844Z","shell.execute_reply":"2024-04-05T20:14:12.237930Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"output = transformer((pt, en))\n\nprint(en.shape)\nprint(pt.shape)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:12.239885Z","iopub.execute_input":"2024-04-05T20:14:12.240238Z","iopub.status.idle":"2024-04-05T20:14:13.021542Z","shell.execute_reply.started":"2024-04-05T20:14:12.240208Z","shell.execute_reply":"2024-04-05T20:14:13.020562Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"(64, 72)\n(64, 78)\n(64, 72, 7010)\n","output_type":"stream"}]},{"cell_type":"code","source":"attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\nprint(attn_scores.shape)  # (batch, heads, target_seq, input_seq)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.022797Z","iopub.execute_input":"2024-04-05T20:14:13.023085Z","iopub.status.idle":"2024-04-05T20:14:13.027960Z","shell.execute_reply.started":"2024-04-05T20:14:13.023060Z","shell.execute_reply":"2024-04-05T20:14:13.027095Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"(64, 8, 72, 78)\n","output_type":"stream"}]},{"cell_type":"code","source":"transformer.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.029269Z","iopub.execute_input":"2024-04-05T20:14:13.029575Z","iopub.status.idle":"2024-04-05T20:14:13.082677Z","shell.execute_reply.started":"2024-04-05T20:14:13.029534Z","shell.execute_reply":"2024-04-05T20:14:13.081845Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Model: \"transformer\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n encoder_1 (Encoder)         multiple                  3632768   \n                                                                 \n decoder_1 (Decoder)         multiple                  5647104   \n                                                                 \n dense_38 (Dense)            multiple                  904290    \n                                                                 \n=================================================================\nTotal params: 10184162 (38.85 MB)\nTrainable params: 10184162 (38.85 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n  def __init__(self, d_model, warmup_steps=4000):\n    super().__init__()\n\n    self.d_model = d_model\n    self.d_model = tf.cast(self.d_model, tf.float32)\n\n    self.warmup_steps = warmup_steps\n\n  def __call__(self, step):\n    step = tf.cast(step, dtype=tf.float32)\n    arg1 = tf.math.rsqrt(step)\n    arg2 = step * (self.warmup_steps ** -1.5)\n\n    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.083723Z","iopub.execute_input":"2024-04-05T20:14:13.083996Z","iopub.status.idle":"2024-04-05T20:14:13.090460Z","shell.execute_reply.started":"2024-04-05T20:14:13.083973Z","shell.execute_reply":"2024-04-05T20:14:13.089523Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"learning_rate = CustomSchedule(d_model)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n                                     epsilon=1e-9)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.091477Z","iopub.execute_input":"2024-04-05T20:14:13.092170Z","iopub.status.idle":"2024-04-05T20:14:13.658638Z","shell.execute_reply.started":"2024-04-05T20:14:13.092146Z","shell.execute_reply":"2024-04-05T20:14:13.657840Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def masked_loss(label, pred):\n  mask = label != 0\n  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n  loss = loss_object(label, pred)\n\n  mask = tf.cast(mask, dtype=loss.dtype)\n  loss *= mask\n\n  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n  return loss\n\n\ndef masked_accuracy(label, pred):\n  pred = tf.argmax(pred, axis=2)\n  label = tf.cast(label, pred.dtype)\n  match = label == pred\n\n  mask = label != 0\n\n  match = match & mask\n\n  match = tf.cast(match, dtype=tf.float32)\n  mask = tf.cast(mask, dtype=tf.float32)\n  return tf.reduce_sum(match)/tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.659720Z","iopub.execute_input":"2024-04-05T20:14:13.660002Z","iopub.status.idle":"2024-04-05T20:14:13.667507Z","shell.execute_reply.started":"2024-04-05T20:14:13.659979Z","shell.execute_reply":"2024-04-05T20:14:13.666587Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"transformer.compile(\n    loss=masked_loss,\n    optimizer=optimizer,\n    metrics=[masked_accuracy])","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.668979Z","iopub.execute_input":"2024-04-05T20:14:13.669855Z","iopub.status.idle":"2024-04-05T20:14:13.690692Z","shell.execute_reply.started":"2024-04-05T20:14:13.669822Z","shell.execute_reply":"2024-04-05T20:14:13.689658Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"transformer.fit(train_batches,\n                epochs=20,\n                validation_data=val_batches)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:13.692033Z","iopub.execute_input":"2024-04-05T20:14:13.692378Z","iopub.status.idle":"2024-04-05T20:14:31.971390Z","shell.execute_reply.started":"2024-04-05T20:14:13.692349Z","shell.execute_reply":"2024-04-05T20:14:31.970150Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class Translator(tf.Module):\n  def __init__(self, tokenizers, transformer):\n    self.tokenizers = tokenizers\n    self.transformer = transformer\n\n  def __call__(self, sentence, max_length=MAX_TOKENS):\n    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n    assert isinstance(sentence, tf.Tensor)\n    if len(sentence.shape) == 0:\n      sentence = sentence[tf.newaxis]\n\n    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n\n    encoder_input = sentence\n\n    # As the output language is English, initialize the output with the\n    # English `[START]` token.\n    start_end = self.tokenizers.en.tokenize([''])[0]\n    start = start_end[0][tf.newaxis]\n    end = start_end[1][tf.newaxis]\n\n    # `tf.TensorArray` is required here (instead of a Python list), so that the\n    # dynamic-loop can be traced by `tf.function`.\n    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n    output_array = output_array.write(0, start)\n\n    for i in tf.range(max_length):\n      output = tf.transpose(output_array.stack())\n      predictions = self.transformer([encoder_input, output], training=False)\n\n      # Select the last token from the `seq_len` dimension.\n      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n\n      predicted_id = tf.argmax(predictions, axis=-1)\n\n      # Concatenate the `predicted_id` to the output which is given to the\n      # decoder as its input.\n      output_array = output_array.write(i+1, predicted_id[0])\n\n      if predicted_id == end:\n        break\n\n    output = tf.transpose(output_array.stack())\n    # The output shape is `(1, tokens)`.\n    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n\n    tokens = tokenizers.en.lookup(output)[0]\n\n    # `tf.function` prevents us from using the attention_weights that were\n    # calculated on the last iteration of the loop.\n    # So, recalculate them outside the loop.\n    self.transformer([encoder_input, output[:,:-1]], training=False)\n    attention_weights = self.transformer.decoder.last_attn_scores\n\n    return text, tokens, attention_weights","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.972419Z","iopub.status.idle":"2024-04-05T20:14:31.972749Z","shell.execute_reply.started":"2024-04-05T20:14:31.972589Z","shell.execute_reply":"2024-04-05T20:14:31.972604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translator = Translator(tokenizers, transformer)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.973981Z","iopub.status.idle":"2024-04-05T20:14:31.974292Z","shell.execute_reply.started":"2024-04-05T20:14:31.974139Z","shell.execute_reply":"2024-04-05T20:14:31.974153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_translation(sentence, tokens, ground_truth):\n  print(f'{\"Input:\":15s}: {sentence}')\n  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n  print(f'{\"Ground truth\":15s}: {ground_truth}')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.975450Z","iopub.status.idle":"2024-04-05T20:14:31.975771Z","shell.execute_reply.started":"2024-04-05T20:14:31.975613Z","shell.execute_reply":"2024-04-05T20:14:31.975627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = 'Eu fiz um monte de trabalho hoje, eu estou super com fome.'\nground_truth = 'i have done a lot of work today, i am super hungry.'\n\ntranslated_text, translated_tokens, attention_weights = translator(\n    tf.constant(sentence))\nprint_translation(sentence, translated_text, ground_truth)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.977682Z","iopub.status.idle":"2024-04-05T20:14:31.978045Z","shell.execute_reply.started":"2024-04-05T20:14:31.977854Z","shell.execute_reply":"2024-04-05T20:14:31.977869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = 'Meu nome é Enrique, sou do México e estou fazendo experimentos.'\nground_truth = 'my name is enrique, i am from mexico and i am doing experiments.'\n\ntranslated_text, translated_tokens, attention_weights = translator(\n    tf.constant(sentence))\nprint_translation(sentence, translated_text, ground_truth)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.979376Z","iopub.status.idle":"2024-04-05T20:14:31.979707Z","shell.execute_reply.started":"2024-04-05T20:14:31.979548Z","shell.execute_reply":"2024-04-05T20:14:31.979563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = 'os resultados são decentes mas não perfeitos.'\nground_truth = 'the results are decent but not perfect.'\n\ntranslated_text, translated_tokens, attention_weights = translator(\n    tf.constant(sentence))\nprint_translation(sentence, translated_text, ground_truth)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.980811Z","iopub.status.idle":"2024-04-05T20:14:31.981162Z","shell.execute_reply.started":"2024-04-05T20:14:31.981005Z","shell.execute_reply":"2024-04-05T20:14:31.981019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = 'quando as frases são simples, os resultados são ótimos.'\nground_truth = 'when the phrases are simple, the results are optimal.'\n\ntranslated_text, translated_tokens, attention_weights = translator(\n    tf.constant(sentence))\nprint_translation(sentence, translated_text, ground_truth)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.982135Z","iopub.status.idle":"2024-04-05T20:14:31.982448Z","shell.execute_reply.started":"2024-04-05T20:14:31.982292Z","shell.execute_reply":"2024-04-05T20:14:31.982306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = 'para o meu próximo projeto vou trabalhar com modelos de difusão.'\nground_truth = 'for my next project i will work with diffusion models.'\n\ntranslated_text, translated_tokens, attention_weights = translator(\n    tf.constant(sentence))\nprint_translation(sentence, translated_text, ground_truth)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.984212Z","iopub.status.idle":"2024-04-05T20:14:31.984536Z","shell.execute_reply.started":"2024-04-05T20:14:31.984379Z","shell.execute_reply":"2024-04-05T20:14:31.984393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.saved_model.save(translator, export_dir='/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.986948Z","iopub.status.idle":"2024-04-05T20:14:31.987285Z","shell.execute_reply.started":"2024-04-05T20:14:31.987129Z","shell.execute_reply":"2024-04-05T20:14:31.987143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/translator')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.989038Z","iopub.status.idle":"2024-04-05T20:14:31.990145Z","shell.execute_reply.started":"2024-04-05T20:14:31.989881Z","shell.execute_reply":"2024-04-05T20:14:31.989921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r myTranslationMachine.zip /kaggle/working/translator","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:14:31.991237Z","iopub.status.idle":"2024-04-05T20:14:31.991678Z","shell.execute_reply.started":"2024-04-05T20:14:31.991449Z","shell.execute_reply":"2024-04-05T20:14:31.991468Z"},"trusted":true},"execution_count":null,"outputs":[]}]}